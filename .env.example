# OpenAI API Key (required when using OpenAI provider)
OPENAI_API_KEY=sk-...

# Default LLM model (optional, default: gpt-4o-mini)
GENAI_WORKFLOW_DEFAULT_MODEL=gpt-4o-mini

# Default temperature for LLM calls (optional, default: 0.7, range: 0.0-2.0)
GENAI_WORKFLOW_DEFAULT_TEMPERATURE=0.7

# Default max tokens for LLM responses (optional, default: 1024)
GENAI_WORKFLOW_DEFAULT_MAX_TOKENS=1024

# Default synchronous execution timeout in seconds (optional, default: no timeout)
# GENAI_WORKFLOW_DEFAULT_TIMEOUT=30.0

# Default execution mode: async or sync (optional, default: async)
GENAI_WORKFLOW_DEFAULT_MODE=async

# Maximum LLM API retry attempts on transient errors (optional, default: 3)
GENAI_WORKFLOW_MAX_RETRIES=3

# Exponential backoff factor for retries (optional, default: 2.0)
GENAI_WORKFLOW_RETRY_BACKOFF=2.0

# Log level: DEBUG, INFO, WARNING, ERROR (optional, default: INFO)
GENAI_WORKFLOW_LOG_LEVEL=INFO

# Log LLM prompts in structured logs (optional, default: false â€” privacy-sensitive)
GENAI_WORKFLOW_LOG_PROMPTS=false
